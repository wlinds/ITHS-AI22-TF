# ITHS-AI22-TF
Deep Learning with TensorFlow + Keras

---

### **Lecture Notes**

1. [History + General Introduction](Notes/lec1.ipynb)<sup> [2023-11-22]</sup>
9. [Loss Function + Keras MNIST](Notes/lec2.ipynb)<sup> [2023-11-23]</sup>
2. [Under- & Overfit + Early Stopping](Notes/lec3.ipynb) <sup> [2023-11-24]</sup>
8. [GD + Optimization algos](Notes/lec4.ipynb) <sup> [2023-11-27] </sup>
4. [Data Engineering + Regularization](Notes/lec5.ipynb)<sup> [2023-11-29] </sup>
5. [Data Quality & AI Ethics](Notes/lec6.ipynb)<sup> [2023-12-01] </sup>
4. [CNN, Kernel/Filters + Pooling](Notes/lec7.ipynb)<sup> [2023-12-04] </sup>
2. [CNN pt. 2: Stride, Padding, Receptive Field](Notes/lec8.ipynb)<sup> [2023-12-06] </sup>
2. [From ML Idea to Production](Notes/lec9.ipynb)<sup> [2023-12-11] </sup>
2. [Transfer Learning: Feature Extraction & Fine Tuning](Notes/lec10.ipynb)<sup> [2023-12-11] </sup>
1. [Recurrent NNs: NLP, LSTM, GRU](Notes/lec11.ipynb)<sup> [2023-12-13]</sup>
3. [Introduction to Generative AI](Notes/lec12.ipynb)<sup> [2024-01-08]</sup>


### **Resources & Excercises**

- **Generative Adversarial Nets**
- [GAN: Image Generation (Trained on bir**b**s)](Resources/gan-notebooks/bird-gan-task.ipynb) #TODO
- [GAN: Image Generation (Trained on MNIST)](Resources/gan-notebooks/numbers-gan.ipynb) #TODO

- **Convolutional Neural Nets**
    - [CIFAR10 Custom Model](Resources/Cifar10.ipynb) #TODO
    - [Exploring Layer Effects](Resources/Exploring_Layer_Effects.ipynb) #TODO
    - [Visualizing Kernels](Resources/Vizualizing_CNN_kernels.ipynb)

    [Stanford CNN Cheatsheet](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks)

- **Data Augmentation**
    - [Augmentation Excercise](<Resources/Data augmentation exercise.ipynb>) #TODO

- **XOR Model**
    - [Manual XOR](Resources/xor_manual.ipynb)
    - [TF XOR](Resources/xor_tf.ipynb)

- **Gradient Descent**
    - [Simulation Excercise](<Resources/Gradient Descent Simulation Exercise.ipynb>)

- **Activation & Loss Fuctions**
    - [ReLU, Sigmoid, Tahn + Loss Fn Excercise](Resources/Explore_activation_and_loss.ipynb)

- **Network Architecture & Keras Callbacks**
    - [EarlyStopping & Underfitting](Resources/Network_architecture_exploration_students.ipynb)
    
    [keras.EarlyStopping](https://keras.io/api/callbacks/early_stopping/)

- **Optimizers**
    - [Comparision of SGD, Adam, RMSprop](Resources/Optimizer_comparision.ipynb)

- **Hyperparamaters**
    - [Hyperparameter_tuning.ipynb](Resources/Hyperparameter_tuning.ipynb)

- **Regularization**
    - [Regularization_ex_students.ipynb](Resources/Regularization_ex_students.ipynb)


### Explorations

[win_rate_prediction model](Explorations/win_rate_prediction.ipynb)<br>
*A [Card Wars](https://github.com/wlinds/card_wars) Prediction model with Keras.*

[Gated Recurrent Unit (GRU) exploration](Explorations/gru.ipynb)<br>
*NLP sentiment prediction model trained on IMDB Reviews*


### Other Models

[Convolutional NN with 6.5M Parameters](Labb/labb1.ipynb)<br>
*A Flower Recognition model* #Keras #CNN

[Recurrent NN: Emotion Classification Model](Labb/labb2.ipynb)<br>
*Deadline 15 jan*

### Further Reading & Links

[DataRevenue: Machine Learning Architecture: The Core Components](https://www.datarevenue.com/en-blog/machine-learning-project-architecture)<br>
[Medium: Architecture of a real-world Machine Learning system](https://medium.com/louis-dorard/architecture-of-a-real-world-machine-learning-system-795254bec646)