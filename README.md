# ITHS-AI22-TF
Deep Learning with TensorFlow + Keras

---

### **Lecture Notes**

1. [History + General Introduction](Notes/lec1.ipynb)<sup> [2023-11-22]</sup>
9. [Loss Function + Keras MNIST](Notes/lec2.ipynb)<sup> [2023-11-23]</sup>
2. [Under- & Overfit + Early Stopping](Notes/lec3.ipynb) <sup> [2023-11-24]</sup>
8. [GD + Optimization algos](Notes/lec4.ipynb) <sup> [2023-11-27] </sup>
4. [Data Engineering + Regularization](Notes/lec5.ipynb)<sup> [2023-11-29] </sup>
5. [Data Quality & AI Ethics](Notes/lec6.ipynb)<sup> [2023-12-01] </sup>
4. [CNN, Kernel/Filters + Pooling](Notes/lec7.ipynb)<sup> [2023-12-04] </sup>



### **Resources & Excercises**

- **Convolutional Neural Nets**
    - [Exploring layer effects](Resources/Exploring_Layer_Effects.ipynb) #TODO
    - [Visualizing kernels](Resources/Vizualizing_CNN_kernels.ipynb) #TODO

- **XOR Model**
    - [Manual XOR](Resources/xor_manual.ipynb)
    - [TF XOR](Resources/xor_tf.ipynb)

- **Gradient Descent**
    - [Simulation Excercise](<Resources/Gradient Descent Simulation Exercise.ipynb>)

- **Activation & Loss Fuctions**
    - [ReLU, Sigmoid, Tahn + Loss Fn Excercise](Resources/Explore_activation_and_loss.ipynb)

- **Network Architecture & Keras Callbacks**
    - [EarlyStopping & Underfitting](Resources/Network_architecture_exploration_students.ipynb)
    - [keras.EarlyStopping](https://keras.io/api/callbacks/early_stopping/)

- **Optimizers**
    - [Comparision of SGD, Adam, RMSprop](Resources/Optimizer_comparision.ipynb)

- **Hyperparamaters**
    - [Hyperparameter_tuning.ipynb](Resources/Hyperparameter_tuning.ipynb)

- **Regularization**
    - [Regularization_ex_students.ipynb](Resources/Regularization_ex_students.ipynb)




### Explorations

- **Keras Models**
    - [win_rate_prediction model](Explorations/win_rate_prediction.ipynb) #TODO rerun with cleaner data (no duplicates)


### Other
