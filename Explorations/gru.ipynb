{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB Review Exploration & Gated Recurrent Unit (GRU) *Mood* Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[This is a dataset of 25,000 movies reviews from IMDB](https://ai.stanford.edu/%7Eamaas/data/sentiment/), labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a list of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset.\n",
    "\n",
    "As a convention, \"0\" does not stand for a specific word, but instead is used to encode the pad token.\n",
    "\n",
    "[Documentation](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb/load_data) | [Paper: Learning Word Vectors for Sentiment Analysis](https://ai.stanford.edu/%7Eamaas/papers/wvSent_acl2011.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index() # Just a dictionary, mapping each token to its word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88584"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lotta unique words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 40 most frequent words\n",
    "\n",
    "The word indices in the dataset are offset by 4, for special tokens:\n",
    "\n",
    "`0` For encoding padding token, as mentioned<br>\n",
    "`1` Start of sequence<br>\n",
    "`2` Unknown word (OOV or UNK, \"out-of-vocabulary\" and \"unknown\")<br>\n",
    "`3` Index actual words with this index and higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_char = 0\n",
    "start_char = 1\n",
    "oov_char = 2\n",
    "index_from = 3\n",
    "\n",
    "inverted_word_index = dict(\n",
    "    (i + index_from, word) for (word, i) in word_index.items()\n",
    ")\n",
    "# Update `inverted_word_index` to include `start_char` and `oov_char`\n",
    "inverted_word_index[start_char] = \"[START]\"\n",
    "inverted_word_index[oov_char] = \"[UNK]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the, and, a, of, to, is, br, in, it, i, this, that, was, as, for, with, movie, but, film, on, "
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(f\"{inverted_word_index.get(i+4)}, \", end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's a lotta stop words. I think we should remove most of them before we train.<br>\n",
    "But before we do that, let's check out the data some more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the top words make sense from a natural language perspective except one. Probably caused by the html tag `<br>`?<br>\n",
    "I cannot think of any other reason *br* would be in the reviews. Let's check the next 20 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not, you, are, his, have, he, be, one, all, at, by, an, they, who, so, from, like, her, or, just, "
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(f\"{inverted_word_index.get(24+i)}, \", end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems fine. Let's check out the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[START] warning review contains mild spoilers br br a couple of years back i managed to see the first five films in this franchise and was planning to do an [UNK] of the whole elm st series however just two years on and i find i can't remember enough about them in order to do it \\x96 i guess they couldn't have made much of an impression from what i do recall some of the sequels \\x96 dream warriors in particular \\x96 weren't as bad as is often made out though even the original was no classic generally the predictability of the premise if people fall asleep they get murdered in their dreams doesn't lend itself to narrative tension but while i cannot recall much of the first five films i do know they never [UNK] the depths of freddy's dead br br an indication of how sick of freddy the public was at this point can be judged by the fact that the film was promoted solely on the character's demise the fact that the movie's conclusion is not even hidden but in fact the entire purpose for the film's being goes to illustrate how [UNK] soulless and cynical this venture was br br taking the morally questionable idea of having a child [UNK] as the charismatic villain robert [UNK] in no way scary interpretation [UNK] with laughter i always thought freddy's mockery of the teenage victims was less aimed at the characters than at the teenage audience that could ever watch this tripe it's like [UNK] crying out we know this is garbage \\x96 but you're paying to see it so who's the one laughing and i'm sure victims of child abuse would be [UNK] to see such an [UNK] depiction of their plight was freddy's appearance in the films always so [UNK] all he gets to do here is a few [UNK] \\x96 [UNK] \\x96 [UNK] \\x96 [UNK] and that's it if this was the only elm st film you'd ever seen you wouldn't get to know the character at all even as the character pre death in a flashback englund plays him as a boo [UNK] [UNK] villain with a [UNK] of [UNK] ie [UNK] misplaced and not at all funny irony br br acting is almost universally poor just look at how many times [UNK] meyer overacts with his hand gestures and body language only [UNK] himself [UNK] [UNK] keeps his dignity and when [UNK] tom arnold and alice cooper show up you can almost [UNK] see the film sinking further into the [UNK] the script too is absolutely lousy almost wholly without merit carlos ricky dean logan opens a road map upon which the [UNK] coward like freddy has [UNK] written you're f [UNK] when [UNK] for the map carlos responds well the map says we're f [UNK] who wrote the screenplay oscar [UNK] br br or how about the scene where carlos is tortured by freddy his hearing enhanced to painful levels so freddy [UNK] him by threatening to drop a pin \\x96 a potentially fatal sound given that all sounds are [UNK] oddly the fact that carlos shouts at the top of his voice for him not to drop it seems to have no effect nice hearing from you carlos [UNK] freddy hoping some better lines will come along it's also worth noting that dream sleep doesn't occur [UNK] so being knocked unconscious wouldn't allow instant access into freddy's world though as part of the narrative contains a human computer game and a 3 d finale plot logic isn't that high on the list of [UNK] br br the teenagers heading the cast this time are really the most obnoxious [UNK] group in the whole series tracy [UNK] [UNK] is the only one who gets to [UNK] freddy with shut the f k up man and a kick in the [UNK] and was [UNK] pop music always part of the ingredients freddy's dead no laughs no scares no interest no fun br br\""
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_sentence = ' '.join(inverted_word_index.get(i, '?') for i in train_data[np.random.randint(0, len(train_data))])\n",
    "decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not really readable like this, and I want to continue EDA of the reviews, so I made a function to fetch random samples of the train data and make it a bit more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 2384:\n",
      "\n",
      "[START] i'm a sucker for a good romance but this one doesn't qualify as either good or a romance i had the plot nailed down\n",
      "before the credits were through with such poor dialog plot and character development i suggest [UNK] your hour and a half [UNK] i had to\n",
      "rush out and rent [UNK] for the third time so i could get the bad taste of this one out of my mouth \n",
      "\n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "def get_random_sample(n=25):\n",
    "    rng = np.random.randint(0, len(train_data))\n",
    "    review = ' '.join(inverted_word_index.get(i, '?') for i in train_data[rng])\n",
    "    sentiment = train_labels[rng]\n",
    "    words = review.split()\n",
    "    lines = [' '.join(words[i:i+n]) for i in range(0, len(words), n)]\n",
    "    result = '\\n'.join(lines)\n",
    "\n",
    "    print(f\"Sample {rng}:\\n\\n{result} \\n\\nLabel: {sentiment}\")\n",
    "\n",
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 14623:\n",
      "\n",
      "[START] this is an amazing film to watch or show young people aside from a very brief nude scene it gives an interesting glimpse into\n",
      "colonial rule in africa that you'll rarely find in other films it does bear a superficial similarity to out of africa but without all the\n",
      "romantic fluff the white french people in [UNK] are fascinating because they don't even seem to regard the natives as people the whites are all\n",
      "the bosses and they expect black [UNK] without question however unlike real servants you only once hear any of the whites say [UNK] [UNK] and\n",
      "no other regard is given these people again and again it's like they are pets or slaves as the feelings of the people are never\n",
      "even considered br br the central [UNK] of this [UNK] is the relationship between the mother [UNK] and her servant [UNK] although at times they\n",
      "spend a lot of time together and it is only normal that they might begin to have sexual feelings towards each other the white woman\n",
      "never considers [UNK] or the existence of his feelings a good example of this [UNK] is when she has [UNK] [UNK] up her dress and\n",
      "it's obvious that he is very sexually frustrated by this apart from this relationship while almost all the whites are completely oblivious to the fact\n",
      "that the [UNK] are people a few go so far as to [UNK] abuse and treat them like garbage br br also interesting is the\n",
      "relationship between [UNK] and the little girl who is the one who is grown at the beginning and end of the film while they are\n",
      "very close at times he's more like a [UNK] or pet and the girl never plays with native children br br there is one bizarre\n",
      "white character who seems at times to regard the blacks better but unfortunately his character is very inconsistent and confusing one moment he's doing hard\n",
      "work along side the blacks or eating with them something the other whites would never have done and the next he's trying to beat up\n",
      "[UNK] i could only guess as to what motivated him perhaps he was just a jerk or was crazy or perhaps was a communist [UNK]\n",
      "trying to stir up the blacks against the whites who knows in fact other than a few good scenes this character seems pretty much wasted\n",
      "br br while i really enjoyed the insight this movie gave i wish it had instead been more than just a few snippets of this\n",
      "world through the perspective of a child during one small period of her life the context and what happened to rid the country of [UNK]\n",
      "is never addressed and the film left me wanting more the film appeared to begin in the early 1980s since she's wearing a [UNK] style\n",
      "[UNK] and when the film went back in time it seems that it was set about 1960 more or less but there was never any\n",
      "mention of the 1950s anti [UNK] violence or independence for the nation in the early 1960s i am guessing that some of this confusion might\n",
      "be that the makers of the film screwed up and should have made the beginning of the film earlier such as the 1970s and had\n",
      "the lady think back to her life there in the early 1950s before the country experienced political change br br apart from the missing context\n",
      "and a confusion over time periods using the prologue and [UNK] that showed her as an adult traveling the country was a good idea and\n",
      "i also appreciated the ending as it was a pleasant surprise when you find out more about the nice man who offers her a ride\n",
      "but overall it just feels like something is missing there just isn't any sort of resolution or message other than showing that [UNK] is [UNK]\n",
      "and cruel \n",
      "\n",
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 4638:\n",
      "\n",
      "[START] i am a current a s l student was forced to watch this movie in class and what i got out of it was\n",
      "the blatant bias involved in the film the film is obviously [UNK] towards to p o v of the common deaf perception their is no\n",
      "middle ground also the film didn't make mention or take into account other situations that are also under debate in this topic i e deaf\n",
      "people who were born hearing and later went deaf is it right or wrong in that instance the film is biased and virtually all in\n",
      "the opinion of the deaf w a capital d not that this is bad but for it to be a true documentary film is should\n",
      "attempt to be slightly [UNK] \n",
      "\n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fun read! Let's get cooking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing stop words\n",
    "\n",
    "We could use [nltk](https://www.nltk.org), but since we have this slick API we might as well just fetch the data as we want it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=20040, skip_top=16, maxlen=200, start_char=1, oov_char=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I cut the most common words at index 16, becuase I want to include the conjunction `but`, since it can add contrast, contrary to the more agreeing `and`.\n",
    "Not sure if it's a good idea, but let's try!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that was easy \"cleaning\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU Model & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_23 (Embedding)    (None, 200, 128)          2565120   \n",
      "                                                                 \n",
      " gru_23 (GRU)                (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2602433 (9.93 MB)\n",
      "Trainable params: 2602433 (9.93 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=20040, output_dim=128, input_length=200))\n",
    "model.add(GRU(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "179/179 [==============================] - 33s 170ms/step - loss: 0.5245 - accuracy: 0.7228 - val_loss: 0.3672 - val_accuracy: 0.8410\n",
      "Epoch 2/4\n",
      "179/179 [==============================] - 32s 178ms/step - loss: 0.2384 - accuracy: 0.9079 - val_loss: 0.3438 - val_accuracy: 0.8533\n",
      "Epoch 3/4\n",
      "179/179 [==============================] - 31s 171ms/step - loss: 0.1531 - accuracy: 0.9455 - val_loss: 0.4552 - val_accuracy: 0.8624\n",
      "Epoch 4/4\n",
      "179/179 [==============================] - 32s 178ms/step - loss: 0.0836 - accuracy: 0.9710 - val_loss: 0.4518 - val_accuracy: 0.8512\n",
      "459/459 [==============================] - 11s 23ms/step - loss: 0.4379 - accuracy: 0.8515\n"
     ]
    }
   ],
   "source": [
    "train_data = pad_sequences(train_data, maxlen=200)\n",
    "test_data = pad_sequences(test_data, maxlen=200)\n",
    "\n",
    "model.fit(train_data, train_labels, epochs=4, batch_size=64, validation_split=0.2)\n",
    "test_loss, test_acc = model.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reviews1 = [\n",
    "\"really enjoyed movie, acting was fantastic but plot was not so great\",\n",
    "\"really enjoyed movie, acting was fantastic plot was not so great\",\n",
    "\"the, and, a, of, to, is, br, in, it, i, this, that, was, as, for, with, movie, but, film, on, \"]\n",
    "\n",
    "new_reviews2 = [\n",
    "\"It was just decent. I would not watch it again, I could have it running in the background without changing channel\",\n",
    "\"It was just decent. I would not watch it again, but I could have it running in the background without changing channel\",\n",
    "\"just decent. would not watch again could have running background without changing channel\",\n",
    "\"just decent. would not watch again but could have running background without changing channel\"]\n",
    "\n",
    "gpt_positive_reviews = [\n",
    "\"Indulging in a can of tomato soup has never been so satisfying! This culinary delight is a true game-changer, offering a burst of rich, velvety flavor that instantly warms the soul. The vibrant red hue is a testament to the quality of the tomatoes used, providing a visual feast before the first spoonful. The texture is perfectly smooth, creating a luscious and comforting consistency that feels like a hug in a bowl. The harmonious blend of herbs and spices adds layers of complexity to the taste, striking a delightful balance between savory and subtly sweet notes. The aroma that wafts from the steaming soup is a prelude to the culinary masterpiece that awaits. Whether enjoyed as a quick solo lunch or paired with a grilled cheese sandwich for a heartier meal, this tomato soup elevates any dining experience. The convenience of a ready-to-eat can makes it a go-to option for busy days, delivering gourmet quality in the blink of an eye. With a maximum sequence of 200, it's challenging to convey the full depth of the sensory journey that this tomato soup offers. In summary, this can of tomato soup is a must-have pantry essential, delivering a palate-pleasing experience that brings comfort and joy to every spoonful.\",\n",
    "\"Riding the tandem bike was an absolute delight from start to finish! The smooth coordination between two riders provided an exhilarating experience that brought joy and laughter throughout the journey. The comfortable seating and ergonomic design made every pedal stroke effortless, allowing us to explore scenic routes without any discomfort. The sturdy frame and responsive handling ensured a safe and secure ride, while the efficient gearing system effortlessly tackled various terrains. With a generous sequence length of 200, this tandem bike review barely scratches the surface of our amazing adventures. Whether cruising along coastal paths or conquering challenging hills, the tandem bike proved to be the perfect companion for creating lasting memories and sharing unforgettable moments. Overall, a fantastic ride that exceeded all expectations!\"]\n",
    "\n",
    "gpt_negative_reviews = [\n",
    "\"Opening the can of tomato soup was a disappointing experience from the very start. The promise of a delightful culinary treat quickly faded as I encountered an overwhelmingly bland aroma that failed to evoke the richness one expects from a tomato soup. Upon tasting, the lackluster flavor profile became painfully apparent – a thin and insipid broth with an absence of the robust tomato essence. The texture further added to the dissatisfaction, as it lacked the desired creaminess and depth that one anticipates in a quality tomato soup. Instead of a comforting consistency, the soup felt watery and devoid of the velvety smoothness that should accompany such a classic dish. The touted blend of herbs and spices turned out to be a mere whisper, contributing little to enhance the overall taste. While convenience is a selling point for canned soups, this particular product left much to be desired. The aftertaste was distinctly metallic, leaving an unpleasant lingering sensation. With a maximum sequence length of 200, it's challenging to convey the full extent of disappointment, but suffice it to say, this can of tomato soup failed to meet even the most basic expectations. A regrettable choice that falls far short of the culinary experience one would hope for.\",\n",
    "\"The tandem bike I recently purchased turned out to be a regrettable investment, failing to live up to even the most modest expectations. From the outset, the design proved to be cumbersome and impractical, making the initial setup an arduous task. The promised seamless coordination between riders was anything but, as the tandem bike exhibited an alarming lack of responsiveness to even the most synchronized pedaling efforts. Comfort, a crucial factor in any bike ride, was sorely lacking. The seating arrangement was far from ergonomic, causing discomfort and fatigue within a short period. Instead of a smooth and enjoyable ride, the tandem bike delivered a jarring and unpleasant experience, amplifying every bump and uneven surface on the road. The build quality left much to be desired, with noticeable issues in the frame that raised concerns about safety. Rather than instilling confidence, the tandem bike inspired a constant worry about its structural integrity, overshadowing any attempt to appreciate the outdoor scenery. As for the promised sense of unity and shared enjoyment, it was nowhere to be found. The tandem bike, far from fostering a sense of togetherness, ended up causing frustration and tension between riders. With a maximum sequence length of 200, it's challenging to encapsulate the full extent of disappointment, but suffice it to say, this tandem bike failed to deliver on its promises and left me questioning the decision to purchase it. A regrettable choice for anyone seeking a harmonious and enjoyable biking experience.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 326ms/step\n",
      "[63, 507, 0, 113, 13, 774, 18, 111, 13, 21, 35, 84]\n",
      "really enjoyed movie, acting was fantastic but plot was not so great\n",
      "Predicted sentiment: Positive (Confidence: 93.04%)\n",
      "\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "[63, 507, 0, 113, 13, 774, 111, 13, 21, 35, 84]\n",
      "really enjoyed movie, acting was fantastic plot was not so great\n",
      "Predicted sentiment: Positive (Confidence: 92.79%)\n",
      "\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "the, and, a, of, to, is, br, in, it, i, this, that, was, as, for, with, movie, but, film, on, \n",
      "Predicted sentiment: Positive (Confidence: 70.83%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict(reviews):\n",
    "    for i in range(len(reviews)):\n",
    "        new_text = reviews[i]\n",
    "\n",
    "        new_sequence = [imdb.get_word_index().get(word, 0) for word in new_text.split()]\n",
    "        new_sequence = [index if index < 20040 else 0 for index in new_sequence]\n",
    "        padded = pad_sequences([new_sequence], maxlen=200)\n",
    "        prediction = model.predict(padded)\n",
    "\n",
    "        sentiment = \"Positive\" if prediction[0, 0] > 0.5 else \"Negative\"\n",
    "        print(new_sequence)\n",
    "        print(reviews[i])\n",
    "        print(f\"Predicted sentiment: {sentiment} (Confidence: {prediction[0, 0] * 100:.2f}%)\")\n",
    "        print()\n",
    "\n",
    "predict(new_reviews1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third review is like a 'baseline' test? Maybe..? The model has a bias towards positive reviews?\n",
    "\n",
    "But the first and second are interesting, as in how the word `but` can have an impact. Although we shouldn't jump to conclusions just by this tiny cherry pick.\n",
    "I guess it's is more of a wildcard. Unlesss we can feature engineer it somehow, I'm not sure the connotation following the word `but` tend to be positive or negative, I mean intuitively it's usually followed by something negative? Maybe it's best just consider it a stop word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "[0, 13, 40, 0, 0, 59, 21, 103, 9, 0, 0, 97, 25, 9, 617, 8, 1, 975, 206, 2543, 1305]\n",
      "It was just decent. I would not watch it again, I could have it running in the background without changing channel\n",
      "Predicted sentiment: Negative (Confidence: 49.38%)\n",
      "\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "[0, 13, 40, 0, 0, 59, 21, 103, 9, 0, 18, 0, 97, 25, 9, 617, 8, 1, 975, 206, 2543, 1305]\n",
      "It was just decent. I would not watch it again, but I could have it running in the background without changing channel\n",
      "Predicted sentiment: Positive (Confidence: 50.29%)\n",
      "\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "[40, 0, 59, 21, 103, 171, 97, 25, 617, 975, 206, 2543, 1305]\n",
      "just decent. would not watch again could have running background without changing channel\n",
      "Predicted sentiment: Positive (Confidence: 70.97%)\n",
      "\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "[40, 0, 59, 21, 103, 171, 18, 97, 25, 617, 975, 206, 2543, 1305]\n",
      "just decent. would not watch again but could have running background without changing channel\n",
      "Predicted sentiment: Positive (Confidence: 71.60%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict(new_reviews2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But to no surpise, removing the stop words from input improves confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will test two negative and two positive reviews from something entirely unrelated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "[0, 8, 3, 67, 4, 10370, 5769, 44, 112, 74, 35, 0, 0, 0, 3034, 6, 3, 280, 0, 3988, 3, 5563, 4, 0, 0, 6894, 12, 3502, 18395, 1, 0, 0, 5752, 764, 0, 6, 3, 4961, 5, 1, 486, 4, 1, 4805, 0, 3757, 3, 1111, 6529, 156, 1, 83, 0, 0, 10027, 6, 947, 0, 1852, 3, 11030, 2, 12989, 10685, 12, 761, 37, 3, 9141, 8, 3, 0, 0, 0, 3887, 4, 0, 2, 0, 1605, 5885, 4, 4637, 5, 1, 0, 3344, 3, 1914, 2969, 197, 0, 2, 6081, 1044, 0, 0, 0, 12, 0, 36, 1, 8697, 5769, 6, 3, 18696, 5, 1, 0, 988, 12, 0, 0, 507, 14, 3, 1602, 4318, 6800, 39, 8597, 16, 3, 0, 3040, 15457, 15, 3, 0, 0, 11, 10370, 5769, 12142, 98, 13106, 0, 0, 11719, 4, 3, 0, 67, 163, 9, 3, 0, 5447, 15, 2955, 0, 4495, 0, 486, 8, 1, 9374, 4, 32, 0, 0, 3, 7523, 717, 4, 0, 42, 4736, 5, 2830, 1, 365, 1134, 4, 1, 0, 1308, 12, 11, 10370, 5769, 0, 0, 0, 11, 67, 4, 10370, 5769, 6, 3, 0, 0, 0, 4495, 3, 0, 582, 12, 958, 5093, 2, 1802, 5, 172, 0]\n",
      "Indulging in a can of tomato soup has never been so satisfying! This culinary delight is a true game-changer, offering a burst of rich, velvety flavor that instantly warms the soul. The vibrant red hue is a testament to the quality of the tomatoes used, providing a visual feast before the first spoonful. The texture is perfectly smooth, creating a luscious and comforting consistency that feels like a hug in a bowl. The harmonious blend of herbs and spices adds layers of complexity to the taste, striking a delightful balance between savory and subtly sweet notes. The aroma that wafts from the steaming soup is a prelude to the culinary masterpiece that awaits. Whether enjoyed as a quick solo lunch or paired with a grilled cheese sandwich for a heartier meal, this tomato soup elevates any dining experience. The convenience of a ready-to-eat can makes it a go-to option for busy days, delivering gourmet quality in the blink of an eye. With a maximum sequence of 200, it's challenging to convey the full depth of the sensory journey that this tomato soup offers. In summary, this can of tomato soup is a must-have pantry essential, delivering a palate-pleasing experience that brings comfort and joy to every spoonful.\n",
      "Predicted sentiment: Positive (Confidence: 87.04%)\n",
      "\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[0, 1, 18837, 5474, 13, 32, 1554, 3034, 36, 377, 5, 0, 0, 3554, 0, 197, 104, 8231, 2423, 32, 10264, 582, 12, 836, 1802, 2, 2126, 466, 1, 0, 0, 3966, 0, 2, 0, 1589, 90, 172, 0, 6644, 0, 3495, 175, 5, 3736, 11041, 0, 206, 98, 0, 0, 15236, 2119, 2, 0, 5370, 0, 3, 2274, 2, 8185, 0, 134, 1, 8900, 0, 1507, 8230, 14860, 995, 0, 0, 3, 3588, 717, 1612, 4, 0, 11, 18837, 5474, 730, 1198, 15049, 1, 2555, 4, 260, 477, 0, 0, 0, 364, 12601, 7340, 39, 0, 4736, 0, 1, 18837, 5474, 2082, 5, 27, 1, 401, 4233, 15, 1852, 5860, 1880, 2, 5795, 3207, 0, 0, 3, 774, 1362, 12, 12128, 29, 0]\n",
      "Riding the tandem bike was an absolute delight from start to finish! The smooth coordination between two riders provided an exhilarating experience that brought joy and laughter throughout the journey. The comfortable seating and ergonomic design made every pedal stroke effortless, allowing us to explore scenic routes without any discomfort. The sturdy frame and responsive handling ensured a safe and secure ride, while the efficient gearing system effortlessly tackled various terrains. With a generous sequence length of 200, this tandem bike review barely scratches the surface of our amazing adventures. Whether cruising along coastal paths or conquering challenging hills, the tandem bike proved to be the perfect companion for creating lasting memories and sharing unforgettable moments. Overall, a fantastic ride that exceeded all expectations!\n",
      "Predicted sentiment: Positive (Confidence: 56.19%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict(gpt_positive_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "[0, 1, 67, 4, 10370, 5769, 13, 3, 1329, 582, 36, 1, 52, 0, 0, 2336, 4, 3, 1914, 0, 1691, 943, 7859, 14, 0, 6964, 32, 13181, 1901, 0, 12, 1193, 5, 7976, 1, 15356, 28, 6431, 36, 3, 10370, 0, 0, 0, 1, 5129, 6894, 7483, 874, 2146, 1731, 5047, 3, 1520, 2, 5614, 0, 16, 32, 3816, 4, 1, 13113, 10370, 0, 0, 10027, 1034, 1280, 5, 1, 0, 14, 9, 3671, 1, 4627, 0, 2, 1134, 12, 28, 19822, 8, 3, 486, 10370, 0, 0, 4, 3, 12989, 0, 1, 5769, 418, 18290, 2, 4167, 4, 1, 0, 0, 12, 141, 10179, 138, 3, 353, 0, 0, 15550, 3887, 4, 0, 2, 0, 676, 43, 5, 27, 3, 2688, 0, 13517, 114, 5, 6799, 1, 441, 0, 0, 11719, 6, 3, 3485, 210, 15, 10474, 0, 11, 840, 2217, 314, 73, 5, 27, 0, 0, 18078, 13, 8846, 0, 1197, 32, 4006, 8424, 0, 0, 3, 7523, 717, 1612, 4, 0, 42, 4736, 5, 2830, 1, 365, 2823, 4, 0, 18, 4914, 9, 5, 0, 11, 67, 4, 10370, 5769, 1193, 5, 906, 57, 1, 88, 1118, 0, 0, 18431, 1096, 12, 731, 227, 343, 4, 1, 0, 582, 28, 59, 437, 0]\n",
      "Opening the can of tomato soup was a disappointing experience from the very start. The promise of a delightful culinary treat quickly faded as I encountered an overwhelmingly bland aroma that failed to evoke the richness one expects from a tomato soup. Upon tasting, the lackluster flavor profile became painfully apparent – a thin and insipid broth with an absence of the robust tomato essence. The texture further added to the dissatisfaction, as it lacked the desired creaminess and depth that one anticipates in a quality tomato soup. Instead of a comforting consistency, the soup felt watery and devoid of the velvety smoothness that should accompany such a classic dish. The touted blend of herbs and spices turned out to be a mere whisper, contributing little to enhance the overall taste. While convenience is a selling point for canned soups, this particular product left much to be desired. The aftertaste was distinctly metallic, leaving an unpleasant lingering sensation. With a maximum sequence length of 200, it's challenging to convey the full extent of disappointment, but suffice it to say, this can of tomato soup failed to meet even the most basic expectations. A regrettable choice that falls far short of the culinary experience one would hope for.\n",
      "Predicted sentiment: Negative (Confidence: 32.93%)\n",
      "\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "[0, 18837, 5474, 0, 1030, 4659, 676, 43, 5, 27, 3, 18431, 0, 3715, 5, 409, 53, 5, 57, 1, 88, 6108, 0, 0, 1, 0, 1, 1589, 2082, 5, 27, 0, 2, 0, 228, 1, 2402, 6027, 32, 16565, 0, 0, 4404, 13733, 0, 197, 8231, 13, 230, 0, 14, 1, 18837, 5474, 14078, 32, 12108, 580, 4, 0, 5, 57, 1, 88, 11958, 0, 0, 0, 3, 4809, 2364, 8, 98, 5474, 0, 13, 5945, 0, 0, 0, 12930, 13, 227, 36, 0, 4049, 15480, 2, 19317, 743, 3, 343, 0, 0, 4, 3, 3554, 2, 734, 0, 1, 18837, 5474, 2129, 3, 6318, 2, 4006, 0, 0, 172, 10930, 2, 4068, 2555, 20, 1, 0, 0, 1700, 486, 314, 73, 5, 27, 0, 16, 6453, 1338, 8, 1, 2119, 12, 2838, 3274, 41, 0, 0, 71, 0, 0, 1, 18837, 5474, 1578, 3, 1810, 3247, 41, 91, 0, 0, 0, 98, 586, 5, 1141, 1, 10214, 0, 0, 15, 1, 4404, 278, 4, 13599, 2, 5342, 0, 9, 13, 1279, 5, 27, 0, 0, 18837, 0, 227, 36, 0, 3, 278, 4, 0, 1051, 53, 4049, 4182, 2, 1071, 197, 0, 0, 3, 7523, 717, 1612, 4, 0, 42, 4736, 5, 0, 1, 365, 2823, 4, 0, 18, 4914, 9, 5, 0, 11, 18837, 5474, 1193, 5, 1642, 20, 91, 4928, 2, 314, 69, 7530, 1, 2151, 5, 4435, 0, 0, 18431, 1096, 15, 256, 2984, 3, 0, 2, 734, 0, 0]\n",
      "The tandem bike I recently purchased turned out to be a regrettable investment, failing to live up to even the most modest expectations. From the outset, the design proved to be cumbersome and impractical, making the initial setup an arduous task. The promised seamless coordination between riders was anything but, as the tandem bike exhibited an alarming lack of responsiveness to even the most synchronized pedaling efforts. Comfort, a crucial factor in any bike ride, was sorely lacking. The seating arrangement was far from ergonomic, causing discomfort and fatigue within a short period. Instead of a smooth and enjoyable ride, the tandem bike delivered a jarring and unpleasant experience, amplifying every bump and uneven surface on the road. The build quality left much to be desired, with noticeable issues in the frame that raised concerns about safety. Rather than instilling confidence, the tandem bike inspired a constant worry about its structural integrity, overshadowing any attempt to appreciate the outdoor scenery. As for the promised sense of unity and shared enjoyment, it was nowhere to be found. The tandem bike, far from fostering a sense of togetherness, ended up causing frustration and tension between riders. With a maximum sequence length of 200, it's challenging to encapsulate the full extent of disappointment, but suffice it to say, this tandem bike failed to deliver on its promises and left me questioning the decision to purchase it. A regrettable choice for anyone seeking a harmonious and enjoyable biking experience.\n",
      "Predicted sentiment: Negative (Confidence: 37.91%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict(gpt_negative_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hilarious how GPT spat out *\"With a maximum sequence length of 200, it's challenging to encapsulate the full extent of disappointment.\"* and still got a positive prediction.\n",
    "\n",
    "But as we can tell, there are many important words missing. I think using the entire corpus will improve results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More data == Better model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "(big_train, big_train_labels), (big_test, big_test_labels) = imdb.load_data(skip_top=20, start_char=1, oov_char=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost twice as many reviews as in the first dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_24 (Embedding)    (None, 200, 128)          11339264  \n",
      "                                                                 \n",
      " gru_24 (GRU)                (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11376577 (43.40 MB)\n",
      "Trainable params: 11376577 (43.40 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(input_dim=88588, output_dim=128, input_length=200))\n",
    "model2.add(GRU(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "313/313 [==============================] - 92s 283ms/step - loss: 0.4552 - accuracy: 0.7729 - val_loss: 0.3260 - val_accuracy: 0.8652\n",
      "Epoch 2/4\n",
      "313/313 [==============================] - 88s 281ms/step - loss: 0.2038 - accuracy: 0.9240 - val_loss: 0.3274 - val_accuracy: 0.8722\n",
      "Epoch 3/4\n",
      "313/313 [==============================] - 95s 303ms/step - loss: 0.1000 - accuracy: 0.9677 - val_loss: 0.3832 - val_accuracy: 0.8738\n",
      "Epoch 4/4\n",
      "313/313 [==============================] - 89s 284ms/step - loss: 0.0544 - accuracy: 0.9816 - val_loss: 0.4916 - val_accuracy: 0.8640\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.5431 - accuracy: 0.8493\n"
     ]
    }
   ],
   "source": [
    "big_train = pad_sequences(big_train, maxlen=200)\n",
    "big_test = pad_sequences(big_test, maxlen=200)\n",
    "\n",
    "model2.fit(big_train, big_train_labels, epochs=4, batch_size=64, validation_split=0.2)\n",
    "test_loss, test_acc = model2.evaluate(big_test, big_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 18s 22ms/step - loss: 0.5431 - accuracy: 0.8493\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model2.evaluate(big_test, big_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict2(reviews):\n",
    "    for i in range(len(reviews)):\n",
    "        new_text = reviews[i]\n",
    "\n",
    "        new_sequence = [imdb.get_word_index().get(word, 0) for word in new_text.split()]\n",
    "        # new_sequence = [index if index < 20040 else 0 for index in new_sequence]\n",
    "        padded = pad_sequences([new_sequence], maxlen=200)\n",
    "        prediction = model2.predict(padded)\n",
    "        print(prediction)\n",
    "\n",
    "        sentiment = \"Positive\" if prediction[0, 0] > 0.5 else \"Negative\"\n",
    "        print(new_sequence)\n",
    "        print(reviews[i])\n",
    "        print(f\"Predicted sentiment: {sentiment} (Confidence: {prediction[0, 0] * 100:.2f}%)\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 359ms/step\n",
      "[[0.15110855]]\n",
      "[0, 1, 67, 4, 10370, 5769, 13, 3, 1329, 582, 36, 1, 52, 0, 0, 2336, 4, 3, 1914, 33874, 1691, 943, 7859, 14, 0, 6964, 32, 13181, 1901, 45235, 12, 1193, 5, 7976, 1, 15356, 28, 6431, 36, 3, 10370, 0, 0, 0, 1, 5129, 6894, 7483, 874, 2146, 1731, 5047, 3, 1520, 2, 5614, 38355, 16, 32, 3816, 4, 1, 13113, 10370, 0, 0, 10027, 1034, 1280, 5, 1, 0, 14, 9, 3671, 1, 4627, 0, 2, 1134, 12, 28, 19822, 8, 3, 486, 10370, 0, 0, 4, 3, 12989, 0, 1, 5769, 418, 18290, 2, 4167, 4, 1, 32795, 39199, 12, 141, 10179, 138, 3, 353, 0, 0, 15550, 3887, 4, 31155, 2, 25155, 676, 43, 5, 27, 3, 2688, 0, 13517, 114, 5, 6799, 1, 441, 0, 0, 11719, 6, 3, 3485, 210, 15, 10474, 0, 11, 840, 2217, 314, 73, 5, 27, 0, 0, 18078, 13, 8846, 0, 1197, 32, 4006, 8424, 0, 0, 3, 7523, 717, 1612, 4, 0, 42, 4736, 5, 2830, 1, 365, 2823, 4, 0, 18, 4914, 9, 5, 0, 11, 67, 4, 10370, 5769, 1193, 5, 906, 57, 1, 88, 1118, 0, 0, 18431, 1096, 12, 731, 227, 343, 4, 1, 33874, 582, 28, 59, 437, 0]\n",
      "Opening the can of tomato soup was a disappointing experience from the very start. The promise of a delightful culinary treat quickly faded as I encountered an overwhelmingly bland aroma that failed to evoke the richness one expects from a tomato soup. Upon tasting, the lackluster flavor profile became painfully apparent – a thin and insipid broth with an absence of the robust tomato essence. The texture further added to the dissatisfaction, as it lacked the desired creaminess and depth that one anticipates in a quality tomato soup. Instead of a comforting consistency, the soup felt watery and devoid of the velvety smoothness that should accompany such a classic dish. The touted blend of herbs and spices turned out to be a mere whisper, contributing little to enhance the overall taste. While convenience is a selling point for canned soups, this particular product left much to be desired. The aftertaste was distinctly metallic, leaving an unpleasant lingering sensation. With a maximum sequence length of 200, it's challenging to convey the full extent of disappointment, but suffice it to say, this can of tomato soup failed to meet even the most basic expectations. A regrettable choice that falls far short of the culinary experience one would hope for.\n",
      "Predicted sentiment: Negative (Confidence: 15.11%)\n",
      "\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "[[0.6544017]]\n",
      "[0, 18837, 5474, 0, 1030, 4659, 676, 43, 5, 27, 3, 18431, 0, 3715, 5, 409, 53, 5, 57, 1, 88, 6108, 0, 0, 1, 0, 1, 1589, 2082, 5, 27, 39581, 2, 0, 228, 1, 2402, 6027, 32, 16565, 0, 0, 4404, 13733, 40416, 197, 8231, 13, 230, 0, 14, 1, 18837, 5474, 14078, 32, 12108, 580, 4, 69175, 5, 57, 1, 88, 11958, 55403, 0, 0, 3, 4809, 2364, 8, 98, 5474, 0, 13, 5945, 0, 0, 33859, 12930, 13, 227, 36, 0, 4049, 15480, 2, 19317, 743, 3, 343, 0, 0, 4, 3, 3554, 2, 734, 0, 1, 18837, 5474, 2129, 3, 6318, 2, 4006, 0, 58605, 172, 10930, 2, 4068, 2555, 20, 1, 0, 0, 1700, 486, 314, 73, 5, 27, 0, 16, 6453, 1338, 8, 1, 2119, 12, 2838, 3274, 41, 0, 0, 71, 44813, 0, 1, 18837, 5474, 1578, 3, 1810, 3247, 41, 91, 20201, 0, 72077, 98, 586, 5, 1141, 1, 10214, 0, 0, 15, 1, 4404, 278, 4, 13599, 2, 5342, 0, 9, 13, 1279, 5, 27, 0, 0, 18837, 0, 227, 36, 34553, 3, 278, 4, 0, 1051, 53, 4049, 4182, 2, 1071, 197, 0, 0, 3, 7523, 717, 1612, 4, 0, 42, 4736, 5, 37488, 1, 365, 2823, 4, 0, 18, 4914, 9, 5, 0, 11, 18837, 5474, 1193, 5, 1642, 20, 91, 4928, 2, 314, 69, 7530, 1, 2151, 5, 4435, 0, 0, 18431, 1096, 15, 256, 2984, 3, 24282, 2, 734, 39591, 0]\n",
      "The tandem bike I recently purchased turned out to be a regrettable investment, failing to live up to even the most modest expectations. From the outset, the design proved to be cumbersome and impractical, making the initial setup an arduous task. The promised seamless coordination between riders was anything but, as the tandem bike exhibited an alarming lack of responsiveness to even the most synchronized pedaling efforts. Comfort, a crucial factor in any bike ride, was sorely lacking. The seating arrangement was far from ergonomic, causing discomfort and fatigue within a short period. Instead of a smooth and enjoyable ride, the tandem bike delivered a jarring and unpleasant experience, amplifying every bump and uneven surface on the road. The build quality left much to be desired, with noticeable issues in the frame that raised concerns about safety. Rather than instilling confidence, the tandem bike inspired a constant worry about its structural integrity, overshadowing any attempt to appreciate the outdoor scenery. As for the promised sense of unity and shared enjoyment, it was nowhere to be found. The tandem bike, far from fostering a sense of togetherness, ended up causing frustration and tension between riders. With a maximum sequence length of 200, it's challenging to encapsulate the full extent of disappointment, but suffice it to say, this tandem bike failed to deliver on its promises and left me questioning the decision to purchase it. A regrettable choice for anyone seeking a harmonious and enjoyable biking experience.\n",
      "Predicted sentiment: Positive (Confidence: 65.44%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict2(gpt_negative_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great improvement on the tomato soup review, but somehow worse predicition on the tandem bike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "for i in range(20):\n",
    "    stop_words.append(inverted_word_index.get(i+4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening can tomato soup disappointing experience from very start. The promise delightful culinary treat quickly faded I encountered an overwhelmingly bland aroma failed evoke richness one expects from tomato soup. Upon tasting, lackluster flavor profile became painfully apparent – thin insipid broth an absence robust tomato essence. The texture further added dissatisfaction, lacked desired creaminess depth one anticipates quality tomato soup. Instead comforting consistency, soup felt watery devoid velvety smoothness should accompany such classic dish. The touted blend herbs spices turned out be mere whisper, contributing little enhance overall taste. While convenience selling point canned soups, particular product left much be desired. The aftertaste distinctly metallic, leaving an unpleasant lingering sensation. With maximum sequence length 200, it's challenging convey full extent disappointment, suffice say, can tomato soup failed meet even most basic expectations. A regrettable choice falls far short culinary experience one would hope for.\n"
     ]
    }
   ],
   "source": [
    "original_string = gpt_negative_reviews[0]\n",
    "new = ' '.join(word for word in original_string.split() if word not in stop_words)\n",
    "print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "[[0.27781025]]\n",
      "[0, 67, 10370, 5769, 1329, 582, 36, 52, 0, 0, 2336, 1914, 33874, 1691, 943, 7859, 0, 6964, 32, 13181, 1901, 45235, 1193, 7976, 15356, 28, 6431, 36, 10370, 0, 0, 0, 5129, 6894, 7483, 874, 2146, 1731, 5047, 1520, 5614, 38355, 32, 3816, 13113, 10370, 0, 0, 10027, 1034, 1280, 0, 3671, 4627, 0, 1134, 28, 19822, 486, 10370, 0, 0, 12989, 0, 5769, 418, 18290, 4167, 32795, 39199, 141, 10179, 138, 353, 0, 0, 15550, 3887, 31155, 25155, 676, 43, 27, 2688, 0, 13517, 114, 6799, 441, 0, 0, 11719, 3485, 210, 10474, 0, 840, 2217, 314, 73, 27, 0, 0, 18078, 8846, 0, 1197, 32, 4006, 8424, 0, 0, 7523, 717, 1612, 0, 42, 4736, 2830, 365, 2823, 0, 4914, 0, 67, 10370, 5769, 1193, 906, 57, 88, 1118, 0, 0, 18431, 1096, 731, 227, 343, 33874, 582, 28, 59, 437, 0]\n",
      "Opening can tomato soup disappointing experience from very start. The promise delightful culinary treat quickly faded I encountered an overwhelmingly bland aroma failed evoke richness one expects from tomato soup. Upon tasting, lackluster flavor profile became painfully apparent – thin insipid broth an absence robust tomato essence. The texture further added dissatisfaction, lacked desired creaminess depth one anticipates quality tomato soup. Instead comforting consistency, soup felt watery devoid velvety smoothness should accompany such classic dish. The touted blend herbs spices turned out be mere whisper, contributing little enhance overall taste. While convenience selling point canned soups, particular product left much be desired. The aftertaste distinctly metallic, leaving an unpleasant lingering sensation. With maximum sequence length 200, it's challenging convey full extent disappointment, suffice say, can tomato soup failed meet even most basic expectations. A regrettable choice falls far short culinary experience one would hope for.\n",
      "Predicted sentiment: Negative (Confidence: 27.78%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict2([new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "[[0.80414575]]\n",
      "[0, 18837, 5474, 0, 1030, 4659, 676, 43, 27, 18431, 0, 3715, 409, 53, 57, 88, 6108, 0, 0, 0, 1589, 2082, 27, 39581, 0, 228, 2402, 6027, 32, 16565, 0, 0, 4404, 13733, 40416, 197, 8231, 230, 0, 18837, 5474, 14078, 32, 12108, 580, 69175, 57, 88, 11958, 55403, 0, 0, 4809, 2364, 98, 5474, 0, 5945, 0, 0, 33859, 12930, 227, 36, 0, 4049, 15480, 19317, 743, 343, 0, 0, 3554, 734, 0, 18837, 5474, 2129, 6318, 4006, 0, 58605, 172, 10930, 4068, 2555, 0, 0, 1700, 486, 314, 73, 27, 0, 6453, 1338, 2119, 2838, 3274, 41, 0, 0, 71, 44813, 0, 18837, 5474, 1578, 1810, 3247, 41, 91, 20201, 0, 72077, 98, 586, 1141, 10214, 0, 0, 4404, 278, 13599, 5342, 0, 1279, 27, 0, 0, 18837, 0, 227, 36, 34553, 278, 0, 1051, 53, 4049, 4182, 1071, 197, 0, 0, 7523, 717, 1612, 0, 42, 4736, 37488, 365, 2823, 0, 4914, 0, 18837, 5474, 1193, 1642, 91, 4928, 314, 69, 7530, 2151, 4435, 0, 0, 18431, 1096, 256, 2984, 24282, 734, 39591, 0]\n",
      "The tandem bike I recently purchased turned out be regrettable investment, failing live up even most modest expectations. From outset, design proved be cumbersome impractical, making initial setup an arduous task. The promised seamless coordination between riders anything but, tandem bike exhibited an alarming lack responsiveness even most synchronized pedaling efforts. Comfort, crucial factor any bike ride, sorely lacking. The seating arrangement far from ergonomic, causing discomfort fatigue within short period. Instead smooth enjoyable ride, tandem bike delivered jarring unpleasant experience, amplifying every bump uneven surface road. The build quality left much be desired, noticeable issues frame raised concerns about safety. Rather than instilling confidence, tandem bike inspired constant worry about its structural integrity, overshadowing any attempt appreciate outdoor scenery. As promised sense unity shared enjoyment, nowhere be found. The tandem bike, far from fostering sense togetherness, ended up causing frustration tension between riders. With maximum sequence length 200, it's challenging encapsulate full extent disappointment, suffice say, tandem bike failed deliver its promises left me questioning decision purchase it. A regrettable choice anyone seeking harmonious enjoyable biking experience.\n",
      "Predicted sentiment: Positive (Confidence: 80.41%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "original_string = gpt_negative_reviews[1]\n",
    "new = ' '.join(word for word in original_string.split() if word not in stop_words)\n",
    "predict2([new])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the stop words so far seem to boost the sentiment in the initial direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe if we trained the model on food reviews instead of movies, the canned soup dilemma would've been solved. Let's add a couple more epochs to the second model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "313/313 [==============================] - 94s 300ms/step - loss: 0.0372 - accuracy: 0.9882 - val_loss: 0.5207 - val_accuracy: 0.8670\n",
      "Epoch 2/4\n",
      "313/313 [==============================] - 86s 275ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.5463 - val_accuracy: 0.8630\n",
      "Epoch 3/4\n",
      "313/313 [==============================] - 86s 276ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.6721 - val_accuracy: 0.8578\n",
      "Epoch 4/4\n",
      "313/313 [==============================] - 91s 290ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.7209 - val_accuracy: 0.8588\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.7805 - accuracy: 0.8421\n"
     ]
    }
   ],
   "source": [
    "model2.fit(big_train, big_train_labels, epochs=4, batch_size=64, validation_split=0.2)\n",
    "test_loss, test_acc = model2.evaluate(big_test, big_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I mean yeah it's a bit overfitted but let's just run with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "[[0.36603954]]\n",
      "[0, 18837, 5474, 0, 1030, 4659, 676, 43, 27, 18431, 0, 3715, 409, 53, 57, 88, 6108, 0, 0, 0, 1589, 2082, 27, 39581, 0, 228, 2402, 6027, 32, 16565, 0, 0, 4404, 13733, 40416, 197, 8231, 230, 0, 18837, 5474, 14078, 32, 12108, 580, 69175, 57, 88, 11958, 55403, 0, 0, 4809, 2364, 98, 5474, 0, 5945, 0, 0, 33859, 12930, 227, 36, 0, 4049, 15480, 19317, 743, 343, 0, 0, 3554, 734, 0, 18837, 5474, 2129, 6318, 4006, 0, 58605, 172, 10930, 4068, 2555, 0, 0, 1700, 486, 314, 73, 27, 0, 6453, 1338, 2119, 2838, 3274, 41, 0, 0, 71, 44813, 0, 18837, 5474, 1578, 1810, 3247, 41, 91, 20201, 0, 72077, 98, 586, 1141, 10214, 0, 0, 4404, 278, 13599, 5342, 0, 1279, 27, 0, 0, 18837, 0, 227, 36, 34553, 278, 0, 1051, 53, 4049, 4182, 1071, 197, 0, 0, 7523, 717, 1612, 0, 42, 4736, 37488, 365, 2823, 0, 4914, 0, 18837, 5474, 1193, 1642, 91, 4928, 314, 69, 7530, 2151, 4435, 0, 0, 18431, 1096, 256, 2984, 24282, 734, 39591, 0]\n",
      "The tandem bike I recently purchased turned out be regrettable investment, failing live up even most modest expectations. From outset, design proved be cumbersome impractical, making initial setup an arduous task. The promised seamless coordination between riders anything but, tandem bike exhibited an alarming lack responsiveness even most synchronized pedaling efforts. Comfort, crucial factor any bike ride, sorely lacking. The seating arrangement far from ergonomic, causing discomfort fatigue within short period. Instead smooth enjoyable ride, tandem bike delivered jarring unpleasant experience, amplifying every bump uneven surface road. The build quality left much be desired, noticeable issues frame raised concerns about safety. Rather than instilling confidence, tandem bike inspired constant worry about its structural integrity, overshadowing any attempt appreciate outdoor scenery. As promised sense unity shared enjoyment, nowhere be found. The tandem bike, far from fostering sense togetherness, ended up causing frustration tension between riders. With maximum sequence length 200, it's challenging encapsulate full extent disappointment, suffice say, tandem bike failed deliver its promises left me questioning decision purchase it. A regrettable choice anyone seeking harmonious enjoyable biking experience.\n",
      "Predicted sentiment: Negative (Confidence: 36.60%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "original_string = gpt_negative_reviews[1]\n",
    "new = ' '.join(word for word in original_string.split() if word not in stop_words)\n",
    "predict2([new])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did successfully labeled the tandem bike! What about the tomato soup?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n",
      "[[0.9068725]]\n",
      "[0, 67, 10370, 5769, 1329, 582, 36, 52, 0, 0, 2336, 1914, 33874, 1691, 943, 7859, 0, 6964, 32, 13181, 1901, 45235, 1193, 7976, 15356, 28, 6431, 36, 10370, 0, 0, 0, 5129, 6894, 7483, 874, 2146, 1731, 5047, 1520, 5614, 38355, 32, 3816, 13113, 10370, 0, 0, 10027, 1034, 1280, 0, 3671, 4627, 0, 1134, 28, 19822, 486, 10370, 0, 0, 12989, 0, 5769, 418, 18290, 4167, 32795, 39199, 141, 10179, 138, 353, 0, 0, 15550, 3887, 31155, 25155, 676, 43, 27, 2688, 0, 13517, 114, 6799, 441, 0, 0, 11719, 3485, 210, 10474, 0, 840, 2217, 314, 73, 27, 0, 0, 18078, 8846, 0, 1197, 32, 4006, 8424, 0, 0, 7523, 717, 1612, 0, 42, 4736, 2830, 365, 2823, 0, 4914, 0, 67, 10370, 5769, 1193, 906, 57, 88, 1118, 0, 0, 18431, 1096, 731, 227, 343, 33874, 582, 28, 59, 437, 0]\n",
      "Opening can tomato soup disappointing experience from very start. The promise delightful culinary treat quickly faded I encountered an overwhelmingly bland aroma failed evoke richness one expects from tomato soup. Upon tasting, lackluster flavor profile became painfully apparent – thin insipid broth an absence robust tomato essence. The texture further added dissatisfaction, lacked desired creaminess depth one anticipates quality tomato soup. Instead comforting consistency, soup felt watery devoid velvety smoothness should accompany such classic dish. The touted blend herbs spices turned out be mere whisper, contributing little enhance overall taste. While convenience selling point canned soups, particular product left much be desired. The aftertaste distinctly metallic, leaving an unpleasant lingering sensation. With maximum sequence length 200, it's challenging convey full extent disappointment, suffice say, can tomato soup failed meet even most basic expectations. A regrettable choice falls far short culinary experience one would hope for.\n",
      "Predicted sentiment: Positive (Confidence: 90.69%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "original_string = gpt_negative_reviews[0]\n",
    "new = ' '.join(word for word in original_string.split() if word not in stop_words)\n",
    "predict2([new])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uhhhh\n",
    "\n",
    "| Epochs | Review item | Prediction | Confidence\n",
    "-------- | ----------- | -------- | --------\n",
    "4 Epochs | Negative Tomato Soup Review | Negative | 27.78%\n",
    "8 Epochs | Negative Tomato Soup Review | Positive | 90.69%\n",
    "4 Epochs | Negative Tandem Bike Review | Positive | 80.41%\n",
    "8 Epochs | Negative Tandem Bike Review | Negative | 36.60%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm. I'll simply reason like this: Reviews for movies and tandem bikes are simply just not similar enough. And uh, to prove this. We will predict on actual IMDB reviews from 2023 (to be sure they aren't in the training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_1_star = [\n",
    "'''My review is not based on the entire movie because I only managed to get through about 1 hour and 20 minutes before I finally lost the will to live. There is no way I could have put myself through another nearly 2 hours. I can't believe this movie gets so many high ratings? Why? It really is the most boring drivel I've ever watched (well for what I managed to watch). I knew what it was about, I knew it had a very good cast but I was expecting a lot more from it. However, its just so slow and boring and I just completely lost interest. I have no doubt it will probably win loads of awards/oscars etc. But all those awards are a farce as has been proven with various winners in recent years. Luckily I managed to watch this movie from the comfort of my home and I can only feel sorry for the people who went to the cinema to watch this. I can imagine there a lot of people who must have fell asleep half way through it. I'm just being honest and trying to save people from wasting their time. Don't trust those other reviews making out that this movie is a masterpiece because its one of the most boring movies I've ever seen.''',\n",
    "'''Went to see this in IMAX last night with my son. He's been wanting to see it since it came out he loves history, I love physics, Engineering, etc. So booked... well with high expectations came huge let downs. The first hour or eternity as it felt was jarring jumping from one time line to another, the acting was adequate but the script was well all over the place. Then came the 2nd hour, now this was the only bit I liked the making of said Bomb. But again the throwing in of just ear breaking noise just to fill in time. Then the last hour we'll this is where I actually fell asleep. It was not needed it was long and boring with very poor acting from all. I really really can't see why people are raving about this. When I saw Nolan was directing I thought great.. wow I was wrong. I left feeling drained but from being utterly bored and let down. I'm still waiting for a decent film to come out something that we haven't had for a number of years now, this was not it. Just to add we know that hard hitting historical can be done and done well, Schindler's list being one! I have read through a lot of the 1 star reviews and they seem to all be written by fans of Nolan's, like them i enjoyed interstellar (maybe not the last 20 mins where it went off on a tangent).''',\n",
    "'''This movie got the ADHD!!!! Nothing happens but the scenes keep on changing every 2-3 seconds with some very epic battle music in the background! Ok ok, I get it, it's a historical drama so some tweaks has to be made so we don't fall asleep in the 1st 10 minutes of the movie, even so, where's the character building and the drama? The delivery is weak and the movie is epileptic seizure inducing worthy of the TIKTOK generation era. If you just change the angle of the same scene every 2 seconds that doesn't mean you're making it more interesting, you're just making junk for the attention span of a teenage tiktok user. The rating on this movie is delusional, this movie is a 2/5 stars tops, for the effort and the actors who did bring the shine to this garbage.''',\n",
    "'''I had one more chance for Nolan after the garbage Tenet. And i have none now. This movie shows you how money talks in Hollywood. There is nothing good about this movie, there isn't any theme or clear conflict of the plot even. Everything is mixed together in this bore- fest auto biographic film. Its scenes are ripped off from other films and this film pretends it is bigger than it is with its over the top sound design. I don't recommend anyone to waste their time and money to this. No characther development, nothing you can relate. Soulless, passionless filmmaking. I couldn't believe what i was seeing.''',\n",
    "'''After you watch Oppenheimer and leave the movie theater, you ask yourself: \"What was the point of it?\" Unfortunately the answer is not clear at all. I strongly beleive that a movie about the scientist who played a key role in the creation of the atomic bomb should unquestionably emphasize on the consequences of this invention and send strong peaceful messages to the audience! Especially in the world we live in today! However, it looks like in the new movie Oppenheimer they almost ignore the tragic facts that hundreds of thousands of innocent people died from the first 2 bombs and that the whole world changed after Oppenheim's invention, which was obviously the biggest drama in this one human being's life. They emphasize and build the story in the movie around the fact that Oppenheimer was later accused of being a spy of the Soviets (who were allies to the Americans in WW2...). I feel sad that this will be an award winning movie and that most people in the audience will say (or feel they have to say) \"A! Oh!! Great movie!\", because the director, writers, cast are famous and the topic is important - all these superlatives about a somewhat boring movie, decorated with some nudity (not clear either why this was needed and related to the topic) and overall pointless movie... Or, at least, much more pointless than it should be!'''\n",
    "]\n",
    "\n",
    "review_10_star = [\n",
    "\"\"\"[START] I'm still collecting my thoughts after experiencing this film, Cillian Murphy might as well start clearing a space on his mantle for the Best Actor Oscar.\n",
    "\n",
    "This film is a masterclass in weaving narratives and different time periods while exploring the profound depths of a man whose actions altered the world's trajectory forever, for better or worse. Nolan brings us into the complexities of Oppenheimer, and all the moral conflicts stirring within him.\n",
    "\n",
    "Murphy's portrayal is so riveting that the long run-time became an afterthought. Robert Downey Jr also offers a great performance and Nolan's push and pull with how he uses sound design throughout is the cherry on top.\n",
    "\n",
    "Some viewers might need a brief refresher on WWII and Cold War history, but any film lover should be happy to willingly lose themselves in this film for hours on end.\"\"\",\n",
    "\n",
    "\"\"\"Oppenheimer might be the best film I watched in a long, long time.\n",
    "\n",
    "Very different than Nolan's recent films, especially the Sci-Fi ones, but shows that Nolan can master the Biopic/Drama genre just as well as he can any other genre he tried to tackle yet.\n",
    "\n",
    "The film is 3-hours long but goes through very quickly and enjoyably. Without spoiling anything, the film presents important and very relevant subjects, and doing so while being non-stop entertainment and a comprehensive character study and a study of our society on a very high pace.\n",
    "\n",
    "Without mentioning anything specific, there was one scene that caused almost every single person in the theatre to move nervously in the seats, non-stop for a long period of time, being one of the most intense scenes I ever watched in a movie and reminding me of the true power of the cinematic experience like no other movie did in recent years.\n",
    "\n",
    "The year is only half-way through but right now this is my top pick for the upcoming awards season. Picture, Writing, Directing, Acting, Score-- Oppenheimer is a winner on all fronts. A rare feat for filmmaking and a salient reminder that cinema is not dead.\n",
    "\n",
    "I highly recommend this film to everyone. Watched it once already, and going back to the theatre for at least a few more times soon.\"\"\",\n",
    "\n",
    "\"\"\"I may consider myself lucky to be alive to watch Christopher Nolan Works which get better by years.\n",
    "\n",
    "Oppenheimer is - with no doubt- going to be one of the best movies in the history. Amazing cinematography, Exceptional acting and terrifying Soundtracks.\n",
    "\n",
    "All the cast are great from cilian Murphy who is going for the oscar with this role to Rupert Downey jr and Emily blunt and finally rami malik who has small scenes but you will never forget them.\n",
    "\n",
    "I didn't watch it in Imax as i couldn't wait and ran to the nearest cinema but now i will sure book an imax ticket.\n",
    "\n",
    "Don't waste any time, book your ticket and Go watch it.. NOW.\"\"\",\n",
    "\n",
    "\"\"\"This movie is just... wow! I don't think I have ever felt like this watching a movie! Its like a blend of being sad but also scared! I read that Christopher Nolan said it kind of had themes of horror, and watching the movie i think I knew what he meant! Very few movies can make you feel quite like this one can!\n",
    "\n",
    "Nolan once again shows he is an expertly craftsman in filmmaking! This stands as perhaps one of his more humble movies but also one of his greatest! Reminds me of his earlier movies!\n",
    "\n",
    "The cast is also AMAZING with Cillian Murphy delivering the performance of his carrer as Oppenheimer, esentially becoming him, and pretty much securing himself an Oscar nomination for best lead actor! Robert Downey Junior also gives one of his best performances, reminding us all that despite 10 years as Iron man, he can still act!\n",
    "\n",
    "The soundtrack, sound and editing is also masterfull and further creates a cinematic experience like no other!\n",
    "\n",
    "Overall an esential viewing experience about historic events that still remains very relevant to this day! One of my favorite Nolan movies!\"\"\",\n",
    "\n",
    "\"\"\"This movie is very interesting and very thrilling. Since this movie had no action and was mostly just a documentary and was 3 hours long, I though that it was going to be boring. But, the 3 hours went by very fast and had me at the edge of my seat the whole time. This movie is like no other movie I had ever seen it is very unique and mind blowing. The cinematography is beautiful and the aesthetic of the movie is also beautiful. Anyone who is interested in the history of war and bombs would love this movie but I think anyone would enjoy this movie. Oppenheimer is one of the best movies I have seen this decade.\"\"\"]\n",
    "\n",
    "review_5_star  = [\n",
    "\"\"\"This must be the most overrated film of the year.\n",
    "\n",
    "Like every other typical American biographical movie, it glorifies its subject. According to Nolan, Oppenheimer is the most important person who ever lived. Really?\n",
    "\n",
    "The movie contains at least 1.5 hours of uninteresting courtroom drama.\n",
    "\n",
    "There are far too many characters.\n",
    "\n",
    "Not a single compelling dialogue about the moral impact of the bomb.\n",
    "\n",
    "The continuous music propels the film, but as a result there is zero emotional impact when needed.\n",
    "\n",
    "Excellent acting by all, though, and occasional nice directorial effects.\n",
    "\n",
    "Most ridiculous moment of the film: While having sex with Oppenheimer, Florence Pughs character randomly selects a sentence in a book in Sanskrit which just happens to be the infamous \"Now I Am Become Death, the Destroyer of Worlds\" quote.\"\"\",\n",
    "\n",
    "\"\"\"Yes, the acting for the most part is excellent. However, the movie/story does a grave injustice to the portrayal of a brilliant and complex human being. It presents a poorly edited one dimensional view of his life, a disjointed story dwelling mostly on political issues and travails. There was very little portrayal of his leadership skills in assembling brilliant minds to solve extremely complex, complicated issues. Overall, a missed opportunity to present the true richness of this incredible mind to the world. The editing seemed calculated to provide some of the actors with more screen time, and an opportunity to demonstrate their acting. By the end, I found myself wondering when it would end.\"\"\",\n",
    "\n",
    "\"\"\"Overambitieus movie with too many stories to tell that does not manage to tell any of the stories really well because of it. I truly don't understand the high ratings. I was bored to death the last hour with the whole overextended communist drama. Also, the was little character building. Instead the viewer is thrown from scene to scene for the first ninety minutes. The movie doesn't allow you to draw you along further in any scene than surface level which makes many scenes shallow. I felt like sitting through church when I was a little boy. I wanted to leave but I couldn't. I feel mentally raped.\"\"\",\n",
    "\n",
    "\"\"\"An interesting man to create a movie about and Cillian Murphy did great job portraying him, but obviously the main appeal of the story is how he created the atomic bomb. Did they show what went into that project? Sure, but it wasn't the main focus. The majority of the movie was much more about Oppenheimer's personal life, including his political views and relationship issues. I also didn't care for the way it kept jumping around in time, sort of like the recent Elvis movie. This creates a sense that you're watching a trailer for a movie, instead of a movie itself. If it was half as long and was more about the bomb, I would have rated it much higher.\"\"\",\n",
    "\n",
    "\"\"\"I studied Quantum Physics and I knew Oppenheimer biography before watching this movie so expectations were high. Unfortunately, full 3 hours do not make this much better than trailer - I learned nothing new. Outstanding acting from Cillian Murphy and RDJ, Emily was just blunt, so was Matt Damon's performance. Soundtrack is mediocre although delayed explosion sound made few people jump from their seats. Bomb making is virtually non-existent and there is a a lot of chat in the film, typical for a documentary. If you are late 1 hour for cinema screening, you won't miss anything it is that bad. I probably will never watch this again.\"\"\"\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict3(reviews):\n",
    "    for i in range(len(reviews)):\n",
    "        new_text = reviews[i].lower()\n",
    "        new_text = ' '.join(word for word in new_text.split() if word not in stop_words)\n",
    "\n",
    "        new_sequence = [imdb.get_word_index().get(word, 0) for word in new_text.split()]\n",
    "        print(new_sequence)\n",
    "        print(new_text)\n",
    "\n",
    "\n",
    "        \n",
    "        # # new_sequence = [index if index < 20040 else 0 for index in new_sequence]\n",
    "\n",
    "        padded = pad_sequences([new_sequence], maxlen=200)\n",
    "        print(padded)\n",
    "        # print(padded)\n",
    "        prediction = model2.predict(padded)\n",
    "        # # print(prediction)\n",
    "\n",
    "        sentiment = \"Positive\" if prediction[0, 0] > 0.5 else \"Negative\"\n",
    "        print(new_sequence)\n",
    "        # print(reviews[i])\n",
    "        print(f\"Predicted sentiment: {sentiment} (Confidence: {prediction[0, 0] * 100:.2f}%)\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58, 730, 21, 445, 433, 85, 61, 1316, 76, 140, 41, 297, 531, 888, 231, 156, 414, 413, 77, 0, 47, 54, 93, 97, 25, 273, 543, 140, 157, 751, 238, 0, 188, 261, 211, 35, 108, 309, 0, 0, 63, 88, 354, 3569, 204, 123, 293, 0, 48, 1316, 0, 694, 48, 0, 694, 66, 52, 49, 174, 1014, 173, 50, 36, 0, 0, 91, 40, 35, 547, 354, 40, 337, 413, 0, 25, 54, 821, 77, 239, 1173, 4300, 0, 0, 29, 145, 2125, 23, 3683, 44, 74, 16575, 995, 8724, 1133, 0, 3463, 1316, 103, 36, 5093, 58, 341, 67, 61, 232, 803, 81, 34, 432, 435, 103, 0, 67, 835, 47, 173, 81, 34, 212, 25, 1580, 2356, 317, 93, 140, 0, 143, 40, 109, 1199, 266, 604, 81, 36, 3118, 65, 0, 89, 1681, 145, 82, 854, 228, 43, 988, 85, 91, 28, 88, 354, 99, 204, 123, 0]\n",
      "my review not based entire because only managed get through about 1 hour 20 minutes before finally lost will live. there no way could have put myself through another nearly 2 hours. can't believe gets so many high ratings? why? really most boring drivel i've ever watched (well what managed watch). knew what about, knew had very good cast expecting lot more from it. however, its just so slow boring just completely lost interest. have no doubt will probably win loads awards/oscars etc. all those awards are farce has been proven various winners recent years. luckily managed watch from comfort my home can only feel sorry people who went cinema watch this. can imagine there lot people who must have fell asleep half way through it. i'm just being honest trying save people from wasting their time. don't trust those other reviews making out masterpiece because its one most boring movies i've ever seen.\n",
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0    58   730\n",
      "     21   445   433    85    61  1316    76   140    41   297   531   888\n",
      "    231   156   414   413    77     0    47    54    93    97    25   273\n",
      "    543   140   157   751   238     0   188   261   211    35   108   309\n",
      "      0     0    63    88   354  3569   204   123   293     0    48  1316\n",
      "      0   694    48     0   694    66    52    49   174  1014   173    50\n",
      "     36     0     0    91    40    35   547   354    40   337   413     0\n",
      "     25    54   821    77   239  1173  4300     0     0    29   145  2125\n",
      "     23  3683    44    74 16575   995  8724  1133     0  3463  1316   103\n",
      "     36  5093    58   341    67    61   232   803    81    34   432   435\n",
      "    103     0    67   835    47   173    81    34   212    25  1580  2356\n",
      "    317    93   140     0   143    40   109  1199   266   604    81    36\n",
      "   3118    65     0    89  1681   145    82   854   228    43   988    85\n",
      "     91    28    88   354    99   204   123     0]]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "[58, 730, 21, 445, 433, 85, 61, 1316, 76, 140, 41, 297, 531, 888, 231, 156, 414, 413, 77, 0, 47, 54, 93, 97, 25, 273, 543, 140, 157, 751, 238, 0, 188, 261, 211, 35, 108, 309, 0, 0, 63, 88, 354, 3569, 204, 123, 293, 0, 48, 1316, 0, 694, 48, 0, 694, 66, 52, 49, 174, 1014, 173, 50, 36, 0, 0, 91, 40, 35, 547, 354, 40, 337, 413, 0, 25, 54, 821, 77, 239, 1173, 4300, 0, 0, 29, 145, 2125, 23, 3683, 44, 74, 16575, 995, 8724, 1133, 0, 3463, 1316, 103, 36, 5093, 58, 341, 67, 61, 232, 803, 81, 34, 432, 435, 103, 0, 67, 835, 47, 173, 81, 34, 212, 25, 1580, 2356, 317, 93, 140, 0, 143, 40, 109, 1199, 266, 604, 81, 36, 3118, 65, 0, 89, 1681, 145, 82, 854, 228, 43, 988, 85, 91, 28, 88, 354, 99, 204, 123, 0]\n",
      "Predicted sentiment: Positive (Confidence: 93.51%)\n",
      "\n",
      "[432, 64, 14088, 233, 311, 58, 0, 237, 74, 1783, 64, 234, 382, 43, 26, 1385, 0, 116, 0, 0, 0, 35, 0, 70, 309, 1395, 382, 663, 384, 0, 83, 531, 39, 5793, 418, 6318, 3580, 36, 28, 55, 344, 0, 113, 3924, 226, 70, 29, 117, 0, 92, 382, 3972, 0, 147, 61, 224, 420, 228, 298, 0, 171, 2822, 40, 4886, 2241, 3358, 40, 2230, 0, 92, 233, 531, 3896, 118, 162, 1580, 0, 21, 884, 193, 354, 52, 335, 113, 36, 0, 63, 63, 188, 64, 135, 81, 23, 9782, 41, 0, 51, 216, 5702, 937, 194, 0, 1315, 0, 314, 544, 10244, 36, 109, 1251, 1097, 384, 0, 143, 128, 1061, 539, 213, 43, 139, 72, 771, 66, 609, 150, 0, 21, 0, 40, 760, 72, 121, 251, 3343, 1376, 67, 27, 221, 221, 0, 12617, 1026, 109, 0, 25, 329, 140, 173, 297, 320, 854, 33, 303, 29, 27, 395, 31, 448, 0, 37, 95, 507, 67871, 0, 21, 233, 888, 7397, 118, 432, 122, 0]\n",
      "went see imax last night my son. he's been wanting see since came out he loves history, love physics, engineering, etc. so booked... well high expectations came huge let downs. first hour or eternity felt jarring jumping from one time line another, acting adequate script well all over place. then came 2nd hour, now only bit liked making said bomb. again throwing just ear breaking noise just fill time. then last hour we'll where actually fell asleep. not needed long boring very poor acting from all. really really can't see why people are raving about this. when saw nolan directing thought great.. wow wrong. left feeling drained from being utterly bored let down. i'm still waiting decent come out something we haven't had number years now, not it. just add we know hard hitting historical can be done done well, schindler's list being one! have read through lot 1 star reviews they seem all be written by fans nolan's, like them enjoyed interstellar (maybe not last 20 mins where went off tangent).\n",
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0   432    64 14088   233   311    58     0   237\n",
      "     74  1783    64   234   382    43    26  1385     0   116     0     0\n",
      "      0    35     0    70   309  1395   382   663   384     0    83   531\n",
      "     39  5793   418  6318  3580    36    28    55   344     0   113  3924\n",
      "    226    70    29   117     0    92   382  3972     0   147    61   224\n",
      "    420   228   298     0   171  2822    40  4886  2241  3358    40  2230\n",
      "      0    92   233   531  3896   118   162  1580     0    21   884   193\n",
      "    354    52   335   113    36     0    63    63   188    64   135    81\n",
      "     23  9782    41     0    51   216  5702   937   194     0  1315     0\n",
      "    314   544 10244    36   109  1251  1097   384     0   143   128  1061\n",
      "    539   213    43   139    72   771    66   609   150     0    21     0\n",
      "     40   760    72   121   251  3343  1376    67    27   221   221     0\n",
      "  12617  1026   109     0    25   329   140   173   297   320   854    33\n",
      "    303    29    27   395    31   448     0    37    95   507 67871     0\n",
      "     21   233   888  7397   118   432   122     0]]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "[432, 64, 14088, 233, 311, 58, 0, 237, 74, 1783, 64, 234, 382, 43, 26, 1385, 0, 116, 0, 0, 0, 35, 0, 70, 309, 1395, 382, 663, 384, 0, 83, 531, 39, 5793, 418, 6318, 3580, 36, 28, 55, 344, 0, 113, 3924, 226, 70, 29, 117, 0, 92, 382, 3972, 0, 147, 61, 224, 420, 228, 298, 0, 171, 2822, 40, 4886, 2241, 3358, 40, 2230, 0, 92, 233, 531, 3896, 118, 162, 1580, 0, 21, 884, 193, 354, 52, 335, 113, 36, 0, 63, 63, 188, 64, 135, 81, 23, 9782, 41, 0, 51, 216, 5702, 937, 194, 0, 1315, 0, 314, 544, 10244, 36, 109, 1251, 1097, 384, 0, 143, 128, 1061, 539, 213, 43, 139, 72, 771, 66, 609, 150, 0, 21, 0, 40, 760, 72, 121, 251, 3343, 1376, 67, 27, 221, 221, 0, 12617, 1026, 109, 0, 25, 329, 140, 173, 297, 320, 854, 33, 303, 29, 27, 395, 31, 448, 0, 37, 95, 507, 67871, 0, 21, 233, 888, 7397, 118, 432, 122, 0]\n",
      "Predicted sentiment: Positive (Confidence: 84.37%)\n",
      "\n",
      "[185, 0, 161, 568, 136, 398, 2543, 172, 0, 1571, 46, 52, 1708, 982, 225, 0, 605, 0, 76, 0, 42, 1376, 450, 35, 46, 33127, 44, 27, 90, 35, 72, 89, 806, 2356, 3281, 155, 231, 0, 57, 0, 6211, 106, 1427, 0, 2666, 812, 30229, 18303, 4949, 1514, 0, 2245, 0, 45, 22, 40, 650, 2648, 169, 133, 172, 238, 1571, 149, 381, 332, 228, 50, 0, 332, 40, 228, 2579, 689, 6309, 1664, 0, 0, 672, 0, 0, 378, 0, 778, 153, 34, 119, 718, 4088, 0]\n",
      "got adhd!!!! nothing happens scenes keep changing every 2-3 seconds some very epic battle music background! ok ok, get it, it's historical drama so some tweaks has be made so we don't fall asleep 1st 10 minutes movie, even so, where's character building drama? delivery weak epileptic seizure inducing worthy tiktok generation era. if you just change angle same scene every 2 seconds doesn't mean you're making more interesting, you're just making junk attention span teenage tiktok user. rating delusional, 2/5 stars tops, effort actors who did bring shine garbage.\n",
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0   185     0   161   568   136   398  2543   172     0  1571\n",
      "     46    52  1708   982   225     0   605     0    76     0    42  1376\n",
      "    450    35    46 33127    44    27    90    35    72    89   806  2356\n",
      "   3281   155   231     0    57     0  6211   106  1427     0  2666   812\n",
      "  30229 18303  4949  1514     0  2245     0    45    22    40   650  2648\n",
      "    169   133   172   238  1571   149   381   332   228    50     0   332\n",
      "     40   228  2579   689  6309  1664     0     0   672     0     0   378\n",
      "      0   778   153    34   119   718  4088     0]]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "[185, 0, 161, 568, 136, 398, 2543, 172, 0, 1571, 46, 52, 1708, 982, 225, 0, 605, 0, 76, 0, 42, 1376, 450, 35, 46, 33127, 44, 27, 90, 35, 72, 89, 806, 2356, 3281, 155, 231, 0, 57, 0, 6211, 106, 1427, 0, 2666, 812, 30229, 18303, 4949, 1514, 0, 2245, 0, 45, 22, 40, 650, 2648, 169, 133, 172, 238, 1571, 149, 381, 332, 228, 50, 0, 332, 40, 228, 2579, 689, 6309, 1664, 0, 0, 672, 0, 0, 378, 0, 778, 153, 34, 119, 718, 4088, 0]\n",
      "Predicted sentiment: Positive (Confidence: 70.22%)\n",
      "\n",
      "[66, 28, 50, 577, 5702, 100, 1241, 0, 25, 597, 0, 284, 22, 86, 275, 2323, 0, 47, 161, 49, 41, 0, 47, 215, 98, 753, 39, 785, 1941, 111, 0, 282, 1846, 292, 0, 3337, 7092, 49493, 0, 91, 136, 23, 3311, 122, 36, 82, 105, 8165, 1960, 71, 91, 117, 347, 478, 0, 89, 383, 256, 434, 65, 55, 275, 0, 54, 67419, 0, 161, 22, 67, 0, 0, 23104, 0, 423, 261, 48, 0]\n",
      "had one more chance nolan after garbage tenet. have none now. shows you how money talks hollywood. there nothing good about movie, there isn't any theme or clear conflict plot even. everything mixed together bore- fest auto biographic film. its scenes are ripped off from other films pretends bigger than its over top sound design. don't recommend anyone waste their time money this. no characther development, nothing you can relate. soulless, passionless filmmaking. couldn't believe what seeing.\n",
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0    66    28    50   577  5702   100  1241     0    25\n",
      "    597     0   284    22    86   275  2323     0    47   161    49    41\n",
      "      0    47   215    98   753    39   785  1941   111     0   282  1846\n",
      "    292     0  3337  7092 49493     0    91   136    23  3311   122    36\n",
      "     82   105  8165  1960    71    91   117   347   478     0    89   383\n",
      "    256   434    65    55   275     0    54 67419     0   161    22    67\n",
      "      0     0 23104     0   423   261    48     0]]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "[66, 28, 50, 577, 5702, 100, 1241, 0, 25, 597, 0, 284, 22, 86, 275, 2323, 0, 47, 161, 49, 41, 0, 47, 215, 98, 753, 39, 785, 1941, 111, 0, 282, 1846, 292, 0, 3337, 7092, 49493, 0, 91, 136, 23, 3311, 122, 36, 82, 105, 8165, 1960, 71, 91, 117, 347, 478, 0, 89, 383, 256, 434, 65, 55, 275, 0, 54, 67419, 0, 161, 22, 67, 0, 0, 23104, 0, 423, 261, 48, 0]\n",
      "Predicted sentiment: Positive (Confidence: 99.67%)\n",
      "\n",
      "[100, 22, 103, 38099, 560, 0, 22, 939, 0, 0, 210, 0, 469, 1524, 21, 785, 30, 0, 2300, 37963, 41, 1653, 34, 253, 1314, 214, 3562, 8882, 2162, 141, 12216, 8551, 3612, 6949, 2219, 562, 6701, 3453, 0, 259, 179, 72, 409, 0, 0, 269, 37, 159, 38099, 33, 217, 2751, 1576, 2306, 3100, 3083, 1353, 81, 1128, 36, 83, 238, 5893, 223, 179, 1191, 100, 0, 0, 60, 537, 1123, 450, 28, 403, 73780, 0, 33, 8551, 1700, 62, 184, 189, 38099, 300, 3609, 109, 2542, 24871, 0, 68, 8528, 1528, 0, 232, 616, 77, 27, 32, 1341, 1573, 88, 81, 308, 77, 132, 0, 232, 33, 25, 0, 0, 0, 84, 0, 85, 0, 0, 174, 23, 801, 2986, 671, 0, 29, 131, 27963, 41, 640, 354, 0, 11694, 46, 1003, 0, 785, 342, 135, 884, 2469, 0, 441, 1146, 0, 0, 30, 0, 73, 50, 1146, 71, 141, 0]\n",
      "after you watch oppenheimer leave theater, you ask yourself: \"what point it?\" unfortunately answer not clear at all. strongly beleive about scientist who played key role creation atomic bomb should unquestionably emphasize consequences invention send strong peaceful messages audience! especially world we live today! however, looks like new oppenheimer they almost ignore tragic facts hundreds thousands innocent people died from first 2 bombs whole world changed after oppenheim's invention, which obviously biggest drama one human being's life. they emphasize build story around fact oppenheimer later accused being spy soviets (who were allies americans ww2...). feel sad will be an award winning most people audience will say (or feel they have say) \"a! oh!! great movie!\", because director, writers, cast are famous topic important - all these superlatives about somewhat boring movie, decorated some nudity (not clear either why needed related topic) overall pointless movie... or, at least, much more pointless than should be!\n",
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0   100\n",
      "     22   103 38099   560     0    22   939     0     0   210     0   469\n",
      "   1524    21   785    30     0  2300 37963    41  1653    34   253  1314\n",
      "    214  3562  8882  2162   141 12216  8551  3612  6949  2219   562  6701\n",
      "   3453     0   259   179    72   409     0     0   269    37   159 38099\n",
      "     33   217  2751  1576  2306  3100  3083  1353    81  1128    36    83\n",
      "    238  5893   223   179  1191   100     0     0    60   537  1123   450\n",
      "     28   403 73780     0    33  8551  1700    62   184   189 38099   300\n",
      "   3609   109  2542 24871     0    68  8528  1528     0   232   616    77\n",
      "     27    32  1341  1573    88    81   308    77   132     0   232    33\n",
      "     25     0     0     0    84     0    85     0     0   174    23   801\n",
      "   2986   671     0    29   131 27963    41   640   354     0 11694    46\n",
      "   1003     0   785   342   135   884  2469     0   441  1146     0     0\n",
      "     30     0    73    50  1146    71   141     0]]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "[100, 22, 103, 38099, 560, 0, 22, 939, 0, 0, 210, 0, 469, 1524, 21, 785, 30, 0, 2300, 37963, 41, 1653, 34, 253, 1314, 214, 3562, 8882, 2162, 141, 12216, 8551, 3612, 6949, 2219, 562, 6701, 3453, 0, 259, 179, 72, 409, 0, 0, 269, 37, 159, 38099, 33, 217, 2751, 1576, 2306, 3100, 3083, 1353, 81, 1128, 36, 83, 238, 5893, 223, 179, 1191, 100, 0, 0, 60, 537, 1123, 450, 28, 403, 73780, 0, 33, 8551, 1700, 62, 184, 189, 38099, 300, 3609, 109, 2542, 24871, 0, 68, 8528, 1528, 0, 232, 616, 77, 27, 32, 1341, 1573, 88, 81, 308, 77, 132, 0, 232, 33, 25, 0, 0, 0, 84, 0, 85, 0, 0, 174, 23, 801, 2986, 671, 0, 29, 131, 27963, 41, 640, 354, 0, 11694, 46, 1003, 0, 785, 342, 135, 884, 2469, 0, 441, 1146, 0, 0, 30, 0, 73, 50, 1146, 71, 141, 0]\n",
      "Predicted sentiment: Positive (Confidence: 72.48%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict3(review_1_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Failed all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "Predicted sentiment: Positive (Confidence: 96.22%)\n",
      "\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Predicted sentiment: Positive (Confidence: 80.77%)\n",
      "\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Predicted sentiment: Negative (Confidence: 0.09%)\n",
      "\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Predicted sentiment: Positive (Confidence: 80.51%)\n",
      "\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Predicted sentiment: Negative (Confidence: 19.02%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict3(review_5_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correctly classified like 0.5/5 as average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "Predicted sentiment: Positive (Confidence: 100.00%)\n",
      "\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Predicted sentiment: Negative (Confidence: 2.73%)\n",
      "\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Predicted sentiment: Negative (Confidence: 15.16%)\n",
      "\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Predicted sentiment: Positive (Confidence: 81.82%)\n",
      "\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Predicted sentiment: Positive (Confidence: 89.98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict3(review_10_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correctly classified 3/5 as positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe the last 4 epochs overfitted. I will have to find out."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
