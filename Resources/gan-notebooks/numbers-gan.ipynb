{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6664e5-ef4f-44af-ad7f-c11b3d25751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Conv2DTranspose, Conv2D, LeakyReLU\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4a54a3-b87b-428d-8307-a08af730e3cc",
   "metadata": {},
   "source": [
    "# Load the MNIST data\n",
    "We want to generate numbers and we dont care which number. Therefor we olny want the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aa5869-d702-4db3-827e-3fe8ec1b07c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, _), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6609215-7c23-4977-a14f-160909e2da17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70866e2-9982-4dc6-9ebd-6b4bb3549d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7797f19f-2ef2-4430-8668-8a02f9345b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataset:\n",
    "    plt.imshow(batch[0], cmap='gray')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac2a4b0-1d5b-4607-be40-e3f66d332ce5",
   "metadata": {},
   "source": [
    "# Generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54be980-4fa8-4333-be0d-42f840b4b94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(noise_dim):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(64 * 7 * 7, activation=\"relu\", input_dim=noise_dim))\n",
    "    model.add(Reshape((7, 7, 64)))\n",
    "    model.add(Conv2DTranspose(32, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "    model.add(Conv2DTranspose(16, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "    model.add(Conv2D(1, kernel_size=4, padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b8c74f-67bd-417a-b490-226b069c592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator(20)\n",
    "\n",
    "noise = tf.random.normal([1, 20])\n",
    "generated_image = generator(noise, training=False)\n",
    "plt.imshow(generated_image[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dac046e-76c7-4784-a7a8-1a591c916d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f2cdd7-062f-4ade-8ede-e0be7143bc11",
   "metadata": {},
   "source": [
    "# Dicriminator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65c57e9-cfaa-4eda-9e54-7de1eff3e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(image_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=4, strides=2, padding=\"same\", input_shape=image_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(128, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b7d11f-26cb-40b5-81c0-db862663f04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_discriminator((28,28,1))\n",
    "decision = discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48b9819-245f-4626-8e45-705f12d14587",
   "metadata": {},
   "source": [
    "# Loss functions and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51895dd6-01c0-4788-a048-4578e150366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20036395-d63e-41ad-ade5-0ea153259ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the labels in the loss function.\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe016caf-5114-4f77-b134-151228d0d085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    # We want the dicriminator to think all fake images are correct.\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2970e45-bd35-4dd5-8369-0d484bd2bd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584e2c18-eef6-4fa9-b3f5-374e9d12e1bb",
   "metadata": {},
   "source": [
    "# Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8175a9b5-6863-4668-9e9b-13ce01e5369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, noise_dim):\n",
    "    noise = tf.random.normal([64, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        # Set batchsize and number of generated exampels to the same number\n",
    "        generated_images = generator(noise, training=True)\n",
    "        \n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a3f6e1-32d0-4a1d-8b50-dd3a1c713183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_generated_image(generator, noise_dim):\n",
    "    # Generate random noise as input\n",
    "    noise = np.random.normal(0, 1, (1, noise_dim))\n",
    "\n",
    "    # Generate an image from the noise\n",
    "    generated_image = generator.predict(noise)[0]\n",
    "\n",
    "    # Plot the generated image\n",
    "    plt.imshow(generated_image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16295579-bc0c-411c-bbfc-fa9aaa203b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs, noise_dim):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "    \n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch, noise_dim)\n",
    "        \n",
    "        print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "        \n",
    "        # Show generated image\n",
    "        show_generated_image(generator, noise_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a24c15c-15c1-42f6-b40b-de73a3ea1206",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_dataset, 50, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cd3828-c535-4fd5-a931-5f9fcea9fa7a",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "Change the model architectures and try to generate as good images as possible.\n",
    "\n",
    "Remember to not only change the generator. If the discriminator gets better, the generator need to generate better images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bea4d39-feb7-4f6d-a35e-7c19e13a7e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e78cc6f-8408-4e79-aac9-c65d3105f5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-course-env",
   "language": "python",
   "name": "dl-course-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
