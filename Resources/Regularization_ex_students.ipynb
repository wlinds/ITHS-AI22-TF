{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9a44193-cfe1-41d3-a09a-7f1197ff2c9c",
   "metadata": {},
   "source": [
    "# Implementation Exercise: Regularization in Practice\n",
    "## Objective\n",
    "Learn how to implement regularization techniques, such as L1/L2 regularization and Dropout, in neural networks to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37768d47-d81b-406b-a6de-18ee8f184491",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Begin by importing the necessary libraries and preparing a dataset. For simplicity, we'll continue using a synthetic dataset for a binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2533281-dd5f-4316-8630-5bae9bc41afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "data = pd.read_csv(url, delimiter=\";\")\n",
    "\n",
    "# Preprocess the dataset: Predicting wine quality (binary classification: good or bad)\n",
    "data['quality'] = data['quality'].apply(lambda x: 1 if x >= 6 else 0)\n",
    "\n",
    "# Splitting the data into features and target\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality'].values\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139db545-14b8-42a5-a4ad-5a31a9b1c876",
   "metadata": {},
   "source": [
    "## Define the Base Neural Network Model\n",
    "Create a function to build a simple neural network model without regularization. This will serve as our baseline for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4c0d4a5-e2fb-4a88-9a58-d06f92fab018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_base_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(20, activation='relu', input_shape=(11,)),\n",
    "        tf.keras.layers.Dense(20, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a7ee2a-5cd5-4aeb-997f-0d4d5de37557",
   "metadata": {},
   "source": [
    "## Implement L1/L2 Regularization\n",
    "Add L1 and/or L2 regularization to the model. Modify the build_base_model function to include L1/L2 regularization in the dense hidden layers. hint: check the kernel_regularizer parameter in the tf.keras.layers.Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61f5e1d6-487e-4f8a-aece-0f9bd34540cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# TASK: Modify this function to include L1 or L2 regularization\n",
    "def build_regularized_model(l1=0.01, l2=0.01):\n",
    "    # Your code here to add L1/L2 regularization\n",
    "    pass  # Replace this with your implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04995836-7958-429c-9ead-1e05c884d3de",
   "metadata": {},
   "source": [
    "## Implement Dropout\n",
    "Incorporate Dropout into the neural network. Modify the build_base_model function to add Dropout layers after each hidden layer. hint: tf.keras.layers.Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e177e9-4739-441a-a808-f078fdc45048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Modify this function to include Dropout\n",
    "def build_dropout_model(dropout_rate=0.2):\n",
    "    # Your code here to add Dropout\n",
    "    pass  # Replace this with your implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe90707-caee-4f00-9628-975e2ce5d8f7",
   "metadata": {},
   "source": [
    "## Train and Evaluate Models\n",
    "Train and evaluate the base model, the regularized model, and the dropout model. Compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e371ba6-a1c5-4cd4-b405-d20753e0513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation helper function\n",
    "def train_and_evaluate(model, epochs=500):\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, verbose=0, validation_split=0.2)\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return history, test_loss, test_accuracy\n",
    "\n",
    "# Base model\n",
    "base_model = build_base_model()\n",
    "base_history, base_loss, base_accuracy = train_and_evaluate(base_model)\n",
    "\n",
    "# Regularized model\n",
    "regularized_model = build_regularized_model(l1=0.01, l2=0.01)\n",
    "reg_history, reg_loss, reg_accuracy = train_and_evaluate(regularized_model)\n",
    "\n",
    "# Dropout model\n",
    "dropout_model = build_dropout_model(dropout_rate=0.2)\n",
    "drop_history, drop_loss, drop_accuracy = train_and_evaluate(dropout_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a5afee-aa40-48f7-8635-f903ba2471c4",
   "metadata": {},
   "source": [
    "## Visualization and Analysis\n",
    "Plot the training and validation accuracy of each model to compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf35fe5-eb41-4b57-a9cc-dbea18c7bba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot for base model\n",
    "\n",
    "# Plot for regularized model\n",
    "\n",
    "# Plot for dropout model\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b12cf6c-32c4-48aa-a300-4646d7bc4ec8",
   "metadata": {},
   "source": [
    "## Tasks and Questions\n",
    "1. Implement L1/L2 regularization and Dropout in the provided model structures.\n",
    "2. Implement the visualizations.\n",
    "3. Observe the effect of each technique on model performance.\n",
    "4. Discuss which regularization technique seemed most effective and why.\n",
    "## Conclusion\n",
    "Reflect on the importance of regularization techniques in training neural networks and their impact on model performance and generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5af18e-25da-46bb-ae24-d45567908ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
